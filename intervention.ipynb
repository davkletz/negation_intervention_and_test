{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [6], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUDA_VISIBLE_DEVICES\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForMaskedLM, AutoModelForCausalLM\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtools\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbuild_array\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_array, build_hypo, build_masked_sentences, build_masked_context\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "import torch\n",
    "from tools.build_array import build_array, build_hypo, build_masked_sentences, build_masked_context\n",
    "from tools.mask_prediction import mask_prediction\n",
    "from random import random, seed\n",
    "from TG_comm import launchFct\n",
    "from tools.chech_conjug import check_conjugation, get_conj\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "path_sentences = \"/home/dkletz/tmp/pycharm_project_99/2022-23/neg-eval-set/en_neg-eval/Inputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroberta-large\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m list_good_patterns_model \u001B[38;5;241m=\u001B[39m \u001B[43mload\u001B[49m( \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_sentences\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/list_good_patterns_mono_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.joblib\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-large\"\n",
    "list_good_patterns_model = load( f\"{path_sentences}/{model_name}/list_good_patterns_mono_{model_name}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForMaskedLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (114416018.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn [10], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    model.to(device)\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model.to(device)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m mask_token \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241m.\u001B[39mmask_token\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "mask_token = tokenizer.mask_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_sentence_cons = \"NOM est MET qui a l'habitude de ACTION. PRON_maj ne MASK vraiment pas souvent.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_good_patterns_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 10\u001B[0m\n\u001B[1;32m      5\u001B[0m total_repetition \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      7\u001B[0m rg_act_tok \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pattern \u001B[38;5;129;01min\u001B[39;00m \u001B[43mlist_good_patterns_model\u001B[49m:\n\u001B[1;32m     11\u001B[0m     name_available \u001B[38;5;241m=\u001B[39m pattern[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_available\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     12\u001B[0m     profession_available \u001B[38;5;241m=\u001B[39m pattern[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprofession_available\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'list_good_patterns_model' is not defined"
     ]
    }
   ],
   "source": [
    "pronouns = {\"She\": \"she\", \"He\": \"he\"}\n",
    "\n",
    "total_sentences = 0\n",
    "\n",
    "total_repetition = 0\n",
    "\n",
    "rg_act_tok = []\n",
    "\n",
    "\n",
    "for pattern in list_good_patterns_model:\n",
    "    name_available = pattern[\"name_available\"]\n",
    "    profession_available = pattern[\"profession_available\"]\n",
    "    verb_available = pattern[\"verb\"]\n",
    "    current_pronouns_maj = pattern[\"current_pronouns_maj\"]\n",
    "    current_pronoun = pronouns[current_pronouns_maj]\n",
    "    \n",
    "    current_hypo_sentence = hypo_sentence_cons\n",
    "            \n",
    "    verb_available_id = tokenizer.encode(verb_available)[1]\n",
    "    verb_available_id = tokenizer.convert_tokens_to_ids([verb_available, f\"Ä {verb_available}\"])\n",
    "    verb_available_id = [k for k in  verb_available_id if k != 3]\n",
    "    if len(verb_available_id) == 1:\n",
    "        verb_available_id = verb_available_id[0]\n",
    "        \n",
    "    masked_sentence = build_masked_sentences(current_hypo_sentence, name_available, profession_available,verb_available,\n",
    "                                                  current_pronouns_maj, current_pronoun, mask_token)\n",
    "    \n",
    "\n",
    "    prediction_conj, mask_token_logits, indice_act, probas_tok = mask_prediction(masked_sentence, tokenizer, model, device, verb_available_id)\n",
    "\n",
    "    rg_act_tok.append(indice_act)\n",
    "\n",
    "\n",
    "    sente_pred = masked_sentence.replace(mask_token, prediction_conj)\n",
    " \n",
    "\n",
    "    if prediction_conj == dico_base[model_name][current_pronouns_maj]:\n",
    "       results_repet[model_name] += 1\n",
    "\n",
    "\n",
    "    if verb_available == prediction_conj or f\" {verb_available}\" == prediction_conj:\n",
    "        total_repetition += 1\n",
    "\n",
    "\n",
    "    total_sentences += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
